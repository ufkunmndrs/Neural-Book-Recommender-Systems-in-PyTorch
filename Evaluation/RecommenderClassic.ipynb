{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project - Comparing Classic Recommender Algorithms with Deep Neural Recommenders\n",
    "Ruprecht-Karls-Universität Heidelberg<br>\n",
    "Institut für Computerlinguistik<br>\n",
    "Seminar: Introduction to Neural Networks and Sequence-to-Sequence Learning<br>\n",
    "Seminarsleitung: Michael Staniek<br>\n",
    "Sommersemester 2020<br>\n",
    "Ufkun-Bayram Menderes<br>\n",
    "\n",
    "## Introduction - Recommender Systems\n",
    "We've been all been there before: We want to make ourselves a cozy winter evening and have prepared snacks and warm blankets to watch the movie of the evening, but at times, we are just overwhelmed with the mere options which we can choose from nowadays on platforms like Hulu or Netflix. I myself haven't experienced it, but apparently not so long ago people decided that they wanted to watch a certain movie, went to their localc Blockbuster, rented the DVD of the movie, watched it, (hopefully) enjoyed it and then safely returned it to their Blockbuster shop. With said platforms like Netflix at our availibity today, this whole procedure has become obsolete, since we can easily click on the respective movie/TV show we want to watch. However, with the meriad of choices available, one might end up just plainly clueless about which movie to watch today. This is the exact point where **Recommender Systems** come into play. What Recommenders do is the following: They track our ratings or consumption patterns on websites such as Netflix and the recommend us items that we, based on our recorded choices of movies, TV shows, Albums etc., might also want to watch and even enjoy to the same extent as we did with our previous items. Regarding this, we might now realize that we have encountered the results of recommender systems and their algorithms more often than not when we're using these platforms, but also online shopping websites like Amazon who never fail us to suggest more items to purchase.<br>\n",
    "In this project, I want to take a closer look at how classical Recommender Algorithms and the newer Neural Recommenders (based on Neural Networks) handle this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Recommender Algorithms\n",
    "Classical Recommender Algorithms work on the premise of two different ways of Recommending: **Item-based Recommendations** and **Collaborative Filtering**. As the names suggest, the former method makes recommendations by comparing items to each other and takes into account how users have rated those items, while the latter forms recommendations by mainly comparing users to each other.\n",
    "\n",
    "The following bulk of code was mainly taken from the book *The Ancient of the Numerati* by Ron Zacharski and was slightly adapted and changed at appropriate places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommender():\n",
    "    def __init__(self, data, k=1, metric='pearson', n=5):\n",
    "        \"\"\"\n",
    "        Recommender class which takes user input data and implements various\n",
    "        functions for both collaborative filtering and item-based filtering\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : dict\n",
    "            is the dictionary in which our data, i.e. the user ratings, are contained\n",
    "        k : int\n",
    "            determines k number of neighbors we are considering for knn calculation,\n",
    "            default is k=1\n",
    "        metric : function\n",
    "            determines the user similarity metric which we are using for \n",
    "            collaborative filtering\n",
    "            The default is 'pearson' metric, other option is cos_similarity\n",
    "        n : int, optional\n",
    "            number of top ratings, the default is 5.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.username2id = {}\n",
    "        self.userid2name = {}\n",
    "        self.productid2name = {}\n",
    "        self.frequencies = {}\n",
    "        self.deviations = {}\n",
    "        self.metric = metric\n",
    "        if self.metric == 'pearson':\n",
    "            self.fn = self.pearson\n",
    "        if self.metric == 'cos_similarity':\n",
    "            self.fn = self.cos_similarity\n",
    "        if type(data).__name__ == 'dict':\n",
    "            self.data = data\n",
    "            \n",
    "    def convertProductID2name(self, id):\n",
    "        \"\"\"\n",
    "        Function which converts given product id's into names\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        id : product id, the key in the dictionary\n",
    "            id of the respective products\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self.productid_to_name[id], id\n",
    "            if the product is in the dictionary, return its value\n",
    "        else simply return id\n",
    "\n",
    "        \"\"\"\n",
    "        #if the key id is in the dictionary\n",
    "        if id in self.productid2name:\n",
    "            #then return its value, which is the product name\n",
    "            return self.productid2name[id]\n",
    "        #else simply return the id\n",
    "        else:\n",
    "            return id\n",
    "    \n",
    "    def user_ratings(self, id, n):\n",
    "        \"\"\"\n",
    "        Function which returns n-top items rated by a user\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        id : user id\n",
    "            id of users for who we will return ratings for\n",
    "        n : int\n",
    "            number of top ratings which will be returned \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        n top ratings\n",
    "\n",
    "        \"\"\"\n",
    "        # user id is the key in our dictionary, its values are the ratings of \n",
    "        # the respective users\n",
    "        # the ratings as values are in themselves again a dictionary with products\n",
    "        # as keys and their ratings as values\n",
    "        print(\"Ratings for: \" + self.userid2name[id])\n",
    "        #s ave those ratings for ever user with an id \n",
    "        ratings = self.data[id]\n",
    "        # print the length of the values\n",
    "        print(len(ratings))\n",
    "        # make a list out of key-value pairs in ratings as tuples\n",
    "        ratings = list(ratings.items())\n",
    "        # call the upper function, pass the keys of the tuples as function \n",
    "        # arguments and make a list comprehension for key-value pairs in the \n",
    "        # tuples\n",
    "        ratings = [(self.convertProductID2name(k), v) for (k, v) in \n",
    "                   ratings]\n",
    "        # sort the list according to the first element of each pair, which is \n",
    "        # the rating, reverse the list so we have top values at the beginning\n",
    "        ratings.sort(key = lambda artist_tuple: artist_tuple[1], reverse=True)\n",
    "        # slice the list up till index n so only n number of elements will be returned\n",
    "        ratings = ratings[:n]\n",
    "        for rating in ratings:\n",
    "            print(\"%s\\t%i\" % (rating[0], rating[1]))\n",
    "            \n",
    "    def load_book_db(self, path=''):\n",
    "        \"\"\"\n",
    "        Function which specifically loads the BX books database/dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : TYPE, optional\n",
    "            DESCRIPTION. The default is ''.\n",
    "            Function that loads our book database\n",
    "            Path is where BX book dataset is located\n",
    "        Each for Loop is for one of the csv-files in our BX-Dump file\n",
    "        1st for-loop: loads book ratings made by users\n",
    "        2nd for-loop: loads book information\n",
    "        3rd for-loop: loads user information\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        # initialize data dict\n",
    "        self.data = {}\n",
    "        # initialize counter\n",
    "        i = 0\n",
    "        # load book ratings into self.data in read mode with utf-8 encoding\n",
    "        f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf-8')\n",
    "        # iterate over each line in the file\n",
    "        # lines are structured as: user-id, isbn, user ratings\n",
    "        for line in f:\n",
    "            i += 1 # increment counter\n",
    "            # separate each line into fields by splitting at semicolon\n",
    "            fields = line.split(\";\")\n",
    "            # extract user-id\n",
    "            user = fields[0].strip('\"')\n",
    "            # extract isbn\n",
    "            book = fields[1].strip('\"')\n",
    "            # extract user rating\n",
    "            rating = int(fields[2].strip().strip('\"'))\n",
    "            \n",
    "            # if the uer in the dictionary\n",
    "            if user in self.data:\n",
    "                # then return his current ratings\n",
    "                current_ratings = self.data[user]\n",
    "            # if not\n",
    "            else:\n",
    "               # create empty ratings dictionary\n",
    "               current_ratings = {}\n",
    "            # inser ratings as values for book keys in ratings dictionary\n",
    "            current_ratings[book] = rating\n",
    "            # assign dict current_ratings as value to key user\n",
    "            self.data[user] = current_ratings\n",
    "        f.close()\n",
    "        # Now load books into self.productid2name\n",
    "        # Books contains isbn, title, and author among other fields\n",
    "        f = codecs.open(path + 'BX-Books.csv', 'r', 'utf-8')\n",
    "        for line in f:\n",
    "            i += 1 #increment counter\n",
    "            fields = line.split(\";\")\n",
    "            isbn = fields[0].strip('\"')\n",
    "            title = fields[1].strip('\"')\n",
    "            author = fields[2].strip('\"')\n",
    "            title = title + ' by ' + author\n",
    "            # assign title as value to key isbn\n",
    "            self.productid2name[isbn] = title\n",
    "        f.close()\n",
    "        #\n",
    "        #  Now load user info into both self.userid2name and\n",
    "        #  self.username2id\n",
    "        #\n",
    "        f = codecs.open(path + 'BX-Users.csv', 'r', 'utf-8')\n",
    "        for line in f:\n",
    "            i += 1 #increment counter\n",
    "            fields = line.split(';')\n",
    "            user_id = fields[0].strip('\"')\n",
    "            location = fields[1].strip('\"')\n",
    "            # if age field is filled with an entry, hence why fields is > 3\n",
    "            if len(fields) > 3:\n",
    "                age = fields[2].strip().strip('\"')\n",
    "            # if not, than enter NULL into age field\n",
    "            else:\n",
    "                age = 'NULL'\n",
    "            # if an entry for age field apparent, enter \n",
    "            if age != 'NULL':\n",
    "                # then concatetenate info into one string\n",
    "                value = location + '  (age: ' + age + ')'\n",
    "            else:\n",
    "                value = location\n",
    "            # assign value as value for key user id in dict\n",
    "            self.userid2name[user_id] = value\n",
    "            # assign user_id as value to key location\n",
    "            self.username2id[location] = user_id\n",
    "        f.close()\n",
    "        print(i)\n",
    "        \n",
    "    def compute_deviations(self):\n",
    "        \"\"\"\n",
    "        Computes item deviations in a given dataset \n",
    "        \n",
    "        args: self, no other argument necessary\n",
    "        \n",
    "        Functions computes deviations for each item according to the given \n",
    "        formula in Chapter 3 of \"The ancient art of Numerati\"\n",
    "        \n",
    "        After function is called, self.deviations will be filled with each item \n",
    "        as key, and its values are dictionaries in which keys represent other items \n",
    "        and values represent the deviation to that item in float type\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        # for each person in the data :\n",
    "        #get their ratings\n",
    "        for ratings in self.data.values():\n",
    "            #for each item and its rating in tthe ratings dict\n",
    "            for (item, rating) in ratings.items():\n",
    "                self.frequencies.setdefault(item, {})\n",
    "                self.deviations.setdefault(item, {})\n",
    "                # for each item2 & rating2 in that set of ratings: \n",
    "                for(item2, rating2) in ratings.items():\n",
    "                    # add the difference between the ratings to our computation\n",
    "                    if item != item2:\n",
    "                        self.frequencies[item].setdefault(item2, 0)\n",
    "                        self.deviations[item].setdefault(item2, 0.0)\n",
    "                        self.frequencies[item][item2] += 1\n",
    "                        self.deviations[item][item2] += rating - rating2\n",
    "        for (item, ratings) in self.deviations.items():\n",
    "            for item2 in ratings:\n",
    "                ratings[item2] /= self.frequencies[item][item2]\n",
    "    \n",
    "        \n",
    "    def slope_one_recommend(self, user):\n",
    "        \"\"\"\n",
    "        Implementation of slope one algorithm for recommendation and \n",
    "        prediction of an item for a given user, for item-based recommendation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            user for which we will recommend items and predict his ratings\n",
    "            self.compute_deviations function must be called before calling this \n",
    "            function\n",
    "            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        recommendations : list\n",
    "            A list containing tuples as elements\n",
    "            tuple[0] = item which user hasn't rated yet, type: str\n",
    "            tuple[1] = predicted rating for that unrated item, type: float\n",
    "\n",
    "        \"\"\"\n",
    "        self.compute_deviations()\n",
    "        recommendations = {}\n",
    "        frequencies = {}\n",
    "        # for every item and rating in the user's recommendations\n",
    "        for (user_item, user_rating) in self.data[user].items():\n",
    "            # for every item in our dataset that the user didn't rate\n",
    "            # example. dict_items([('Taylor Swift', 5), ('PSY', 2)])\n",
    "            for (diff_item, diff_ratings) in self.deviations.items():\n",
    "                if diff_item not in self.data[user] and \\\n",
    "                   user_item in self.deviations[diff_item]:\n",
    "                # get the deviations, frequencies for the item that wasn't rated\n",
    "                # but only if a value for deviations exists and diff_item is not \n",
    "                # in user_ratings\n",
    "                    freq = self.frequencies[diff_item][user_item]\n",
    "                    # get the frequency of diff_item and user_item, \n",
    "                    # key in frequencies is the different item, second dict indice \n",
    "                    # is the frequency with user_item\n",
    "                    recommendations.setdefault(diff_item, 0.0)\n",
    "                    frequencies.setdefault(diff_item, 0)\n",
    "                    # add to the running sum representing the numerator\n",
    "                    # of the formula \n",
    "                    # diff_item is key, result of formula is value\n",
    "                    recommendations[diff_item] += (diff_ratings[user_item] +\n",
    "                                                   user_rating)* freq\n",
    "                    # keep a running sum of the frequency of diffitem\n",
    "                    frequencies[diff_item] += freq\n",
    "        recommendations = [(self.convertProductID2name(k), v / frequencies[k])\n",
    "                           for (k, v) in recommendations.items()]\n",
    "        recommendations.sort(key=lambda artist_tuple: artist_tuple[1], reverse = True)\n",
    "        return recommendations\n",
    "    \n",
    "    \n",
    "    \n",
    "    def minkowski_distance(self, rating1, rating2, p):\n",
    "        \"\"\"\n",
    "        Implementation of Minkowski distance formula\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rating1 : dict\n",
    "            dictionary in which the ratings of user1 are specified, \n",
    "            passing as argument into function via \"users['users']\"\n",
    "        rating2 : dict\n",
    "            dictionary in which ratings of user2 are specified, same \n",
    "            argument passing conventions as above\n",
    "        p : int\n",
    "            specifies parameter 'p' in minkowski distance formula\n",
    "            p = 1 --> Manhattan distance\n",
    "            p = 2 --> Euclidean distance\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            returns the minkowski distance measure between rating1 and rating 2\n",
    "            according to parameter 'p'\n",
    "\n",
    "        \"\"\"\n",
    "        distance = 0\n",
    "        common_ratings = False\n",
    "        for key in rating1:\n",
    "            if key in rating2:\n",
    "                distance += pow(abs(rating1[key] - rating2[key]), p)\n",
    "                common_ratings = True\n",
    "        if common_ratings == True:\n",
    "            return pow(distance, 1/p)\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "        \n",
    "        \n",
    "    def pearson(self, rating1, rating2):\n",
    "        \"\"\"\n",
    "        Implementation of Pearson correlation coefficient formula\n",
    "        Calculates similarity of users via ratings ina given dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rating1 : dict\n",
    "            ratings of the first user, access via \"users[user]\"\n",
    "        rating2 : dict\n",
    "            ratings of 2nd user, same accessing conventions when passing \n",
    "            in the argument\n",
    "        function implements pearson similarity metric by comparing commonly rated \n",
    "        elements of both users\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            returns a float which measures the similarity of two user according \n",
    "            to their set of commonly given ratings, ranges from -1 to 1\n",
    "\n",
    "        \"\"\"\n",
    "        sum_xy = 0\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        sum_x2 = 0\n",
    "        sum_y2 = 0\n",
    "        n = 0\n",
    "        for key in rating1:\n",
    "            if key in rating2:\n",
    "                n += 1\n",
    "                x = rating1[key]\n",
    "                y = rating2[key]\n",
    "                sum_xy += x * y\n",
    "                sum_x += x\n",
    "                sum_y += y\n",
    "                sum_x2 += pow(x, 2)\n",
    "                sum_y2 += pow(y, 2)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        # compute denominator\n",
    "        denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)\n",
    "                       * sqrt(sum_y2 - pow(sum_y, 2) / n))\n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (sum_xy - (sum_x * sum_y) / n) / denominator\n",
    "    \n",
    "    def dot(self, rating1, rating2):\n",
    "        \"\"\"\n",
    "        Computes the dot product SPECIFICALLY for our application\n",
    "        at hand and without using numpy data structures\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rating1 : dict\n",
    "            dict containing user ratings for user 1, must be indiced in the form \n",
    "            of 'users[user]' as function argument in order to properly access user \n",
    "            ratings\n",
    "        rating2 : dict\n",
    "            dict containing user ratings for user 2, same as above for indicing\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dot : float\n",
    "            returns the dot product for 2 users \n",
    "\n",
    "        \"\"\"\n",
    "        for key in rating1:\n",
    "            if key in rating2:\n",
    "                dot = sum(rating1[key]*rating2.get(key, 0) for key in rating1)\n",
    "        return dot\n",
    "    \n",
    "    def cos_similarity(self, rating1, rating2):\n",
    "        \"\"\"\n",
    "        Implementation of cosine similarity w.r.t to given datastructures at hand\n",
    "        Measures similarity between two users by measuring ratings\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rating1 : dict \n",
    "            user ratings for user 1, dict must be indiced and indexing must be \n",
    "            passed as function argument in form of (users['user'])\n",
    "        rating2 : dict\n",
    "            user ratings for user 2, same as above \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cosine similarity\n",
    "            alternative measure for capturing the similarity between two users, \n",
    "            ranges from 0 to 1\n",
    "\n",
    "        \"\"\"\n",
    "        num = self.dot(rating1, rating2)\n",
    "        sum_r1 = []\n",
    "        sum_r2 = []\n",
    "        for vals in rating1.values():\n",
    "            sum_r1.append(pow(vals, 2))\n",
    "        for vals in rating2.values():\n",
    "            sum_r2.append(pow(vals, 2))\n",
    "            denom = sqrt(sum(sum_r1)) * sqrt(sum(sum_r2))\n",
    "        return num / denom\n",
    "        \n",
    "        \n",
    "    def averages(self, users):\n",
    "        \"\"\"\n",
    "        Computes average ratings assigned by users in a given dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        users : dict\n",
    "            Dictionary in which users as keys and their respective ratings for \n",
    "            the respective items (dict) as values are stored\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : dict\n",
    "            users are keys, their average ratings (float) are values\n",
    "\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for (key, ratings) in users.items():\n",
    "            results[key] = float(sum(ratings.values())) / len(ratings.values())\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    \n",
    "    def item_similarity(self, artist1, artist2, user_ratings):\n",
    "        \"\"\"\n",
    "        Computes the similarity between two items in a given dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        artist1 : str\n",
    "            artist1 for which we will compute the similarity with artist2, must be \n",
    "            in user_ratings dict\n",
    "        artist2 : str\n",
    "            artist1 for which we will compute the similarity with artist2, must be \n",
    "            in user_ratings dict    \n",
    "        user_ratings : dict\n",
    "            dictionary containing users as keys, their ratings for items \n",
    "            as internal dict as values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            similarity between two items\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        averages = {}\n",
    "        for (key, ratings) in user_ratings.items():\n",
    "            #take the values of the internal dict, sum over each value and divide by length of values\n",
    "            averages[key] = (float(sum(ratings.values()))\n",
    "                      / len(ratings.values()))\n",
    "        numerator = 0\n",
    "        denom1 = 0\n",
    "        denom2 = 0\n",
    "        for (user, ratings) in user_ratings.items():\n",
    "            #if the users rated both artists\n",
    "            if artist1 in ratings and artist2 in ratings:\n",
    "                #compute the averages of each user\n",
    "                avg = averages[user]\n",
    "                # in ratings dict, artists are the keys and their respective values, \n",
    "                # which we access via indexing, are their ratings\n",
    "                # those ratings for the artists are subtracted by the average of each user\n",
    "                # and then multiplied\n",
    "                numerator += (ratings[artist1] - avg) * (ratings[artist2] - avg)\n",
    "                denom1 += (ratings[artist1]-avg)**2 \n",
    "                denom2 += (ratings[artist2]-avg)**2\n",
    "        return numerator / (sqrt(denom1) * sqrt(denom2))\n",
    "    \n",
    "    def normalized_rating(self, user:str, item:str):\n",
    "        \"\"\"\n",
    "        Normalizes the rating of an item for a user in a given dataset according \n",
    "        to minimum and maximum rating of that dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            a user who has rated the item function argument\n",
    "        item : str\n",
    "            item that a user has rated, is within the internal dictionary as key\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            normalized rating for a user given said item\n",
    "\n",
    "        \"\"\"\n",
    "        global min_rat\n",
    "        global max_rat\n",
    "        min_ratings = []\n",
    "        max_ratings = []\n",
    "        for (key, rating) in self.data.items():\n",
    "            key_max = max(rating.keys(), key=(lambda k: rating[k]))\n",
    "            key_min = min(rating.keys(), key=(lambda k: rating[k]))\n",
    "            min_ratings.append(rating[key_min])\n",
    "            max_ratings.append(rating[key_max])\n",
    "        min_rat = min(min_ratings)\n",
    "        max_rat = max(max_ratings)\n",
    "        if item in self.data[user]:\n",
    "            return (2*((self.data[user][item]-min_rat)) - (max_rat-min_rat)) / (max_rat-min_rat)\n",
    "            \n",
    "    \n",
    "    def denormalized_rating(self, user:str, item:str):\n",
    "        \"\"\"\n",
    "        Returns a normalized rating back into a scaled rating, \n",
    "        given respective rating scale\n",
    "        \n",
    "        BEWARE!!! This function takes an user and an item and then gives the denormalized\n",
    "        rating for it, the denormalizer only takes a float value\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            DESCRIPTION.\n",
    "        norm_rating : float\n",
    "            DESCRIPTION.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        return (0.5*((self.normalized_rating(user, item)+1) * (max_rat-min_rat))) + min_rat\n",
    "        \n",
    "    \n",
    "    def denormalize(self, norm_rating:float):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        norm_rating : float\n",
    "            DESCRIPTION.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        return (0.5*((norm_rating+1) * (max_rat-min_rat))) + min_rat\n",
    "\n",
    "        \n",
    "    def predict_rating(self, user:str, item:str):\n",
    "        \"\"\"\n",
    "        Predicts the rating of an item from a user from a given dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            user in a given dataset\n",
    "        item : str\n",
    "            an item which the user HAS NOT rated yet\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            tuple[0] = user \n",
    "            tuple[1] = item recommended for that user\n",
    "            tuple[2] = predicted rating for that item\n",
    "\n",
    "        \"\"\"\n",
    "        #initiate numerator and denumerator of formula\n",
    "        denom = 0\n",
    "        numerator = 0\n",
    "        for rated_item in self.data[user]:\n",
    "            if rated_item in self.data[user]:\n",
    "                denom += (self.item_similarity(rated_item, item, self.data)\n",
    "                          *self.normalized_rating(user, rated_item))\n",
    "                numerator += abs(self.item_similarity(item, rated_item, self.data))\n",
    "        return (user, item, self.denormalize(denom/numerator))\n",
    "   \n",
    "        \n",
    "        \n",
    "            \n",
    "    def nearest_neighbor(self, username):\n",
    "        \"\"\"\n",
    "        Determines nearest neighbors, i.e. users for a user in a given dataset\n",
    "        for collaborative filtering.\n",
    "        Default metric is Pearson correlation coefficient, can be changed to other\n",
    "        metrics when instatiating an object of Recommender class \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        username : str\n",
    "            username of a user in the set of our users\n",
    "        \n",
    "        since self.fn == 'pearson', the nearest neighbors will be calculated \n",
    "        using pearson coefficient, can be changed if desired\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        distances : list\n",
    "            a list containing all the distances from the user to the other users\n",
    "            in the total set of users\n",
    "            Elements are tuples with users (str) as first element and the distances\n",
    "            to them as floats as second element\n",
    "\n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        for instance in self.data:\n",
    "            # measure distance only if users are distinct \n",
    "            if instance != username:\n",
    "                # Pearson metric is applied\n",
    "                distance = self.fn(self.data[username], self.data[instance])\n",
    "                distances.append((instance, distance))\n",
    "        distances.sort(key=lambda artist_tuple: artist_tuple[1], reverse=True)\n",
    "        return distances\n",
    "    \n",
    "    def recommend(self, user:str):\n",
    "        \"\"\"\n",
    "        Recommends a \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            user in the set of users\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        type = list\n",
    "            returns a list of top n recommendations for the user \n",
    "\n",
    "        \"\"\"\n",
    "        # create empty dictionary for recommendations\n",
    "        recommendations = {}\n",
    "        # compute the nearest neighbors of a specific user\n",
    "        nearest = self.nearest_neighbor(user)\n",
    "        # extract ratings for this specific user from self.data dict\n",
    "        user_ratings = self.data[user]\n",
    "        # initialize total distance counter\n",
    "        total_distance = 0.0\n",
    "        # iterate over k elements, here k=1\n",
    "        for i in range(self.k):\n",
    "            total_distance += nearest[i][1]\n",
    "        # add up the total distance by summing over the ratings of k nearest neighbors\n",
    "        # compute the contribution of each k neighbor\n",
    "        for i in range(self.k):\n",
    "            weight = nearest[i][1] / total_distance\n",
    "            # extract name of each of the k neighbors\n",
    "            name = nearest[i][0]\n",
    "            # extract ratings of each person out of the k neighbors\n",
    "            neighbor_ratings = self.data[name]\n",
    "        # for every artist in neighbor ratings\n",
    "        for artist in neighbor_ratings:\n",
    "            # if the artist is not in the user_ratings\n",
    "            if not artist in user_ratings:\n",
    "                # and if the artist is not already in recommendations dict \n",
    "                # i.e. artists that the neigbor rated but the user didn't\n",
    "                # for key artists, assign the value of its neighbor rating times the weight \n",
    "                # it contributes\n",
    "                if artist not in recommendations:\n",
    "                    # for key artists, assign the value of its neighbor rating times the weight \n",
    "                    # it contributes\n",
    "                    recommendations[artist] = (neighbor_ratings[artist]*weight)\n",
    "                else:\n",
    "                    # if artist already existing, assign neighbor rating + recommendations rating\n",
    "                    # and multiply it with weight\n",
    "                    recommendations[artist] = (recommendations[artist]+neighbor_ratings[artist] * weight)\n",
    "        # make a list out of the key, value pairs of artist and recommendations tuples\n",
    "        recommendations = list(recommendations.items())\n",
    "        # convert the product id to names via list comprehension\n",
    "        recommendations = [(self.convertProductID2name(k), v) for (k, v) in recommendations]\n",
    "        # sort the list by rating, reverse in order for top ratings to be at the beginning\n",
    "        recommendations.sort(key=lambda artist_tuple: artist_tuple[1], reverse=True)\n",
    "        # return n elements\n",
    "        return recommendations[:self.n]\n",
    "    \n",
    "    def nearest_items(self, user:str):\n",
    "        \"\"\"\n",
    "        Recommends an item to a user by recommending the most similar item \n",
    "        to highest rated items by a user\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            user for which we will the items most similar to his top rated item\n",
    "            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "        tuple[1] = user, str\n",
    "        tuple[2] = recommendations, list       \n",
    "\n",
    "        \"\"\"\n",
    "        # compute deviations since self.deviations will be useful for \n",
    "        # future calculatios\n",
    "        self.compute_deviations()\n",
    "        # sort ratings of a user\n",
    "        top_rated = {item: rating for item, rating in \n",
    "                     sorted(self.data[user].items(), key=lambda value: value[1],\n",
    "                            reverse=True)}\n",
    "        # discard all elements which are not top rated\n",
    "        for key, rating in top_rated.items():\n",
    "            # determine highest rated item(s) and their rating(s)\n",
    "            max_user_rating = max(top_rated.keys(), key=(lambda k: top_rated[k]))\n",
    "            max_user_rating = top_rated.get(max_user_rating)\n",
    "            #finding elements with multiple values\n",
    "            mult_top_rated = [k for k, v in top_rated.items() if v == max_user_rating]\n",
    "        # now we find the most similar item for each top rated item of a user\n",
    "        similarities = []\n",
    "        for item in mult_top_rated:\n",
    "            for unrated_item in self.deviations:\n",
    "                if unrated_item not in top_rated:\n",
    "                    item_sim = self.item_similarity(item, unrated_item, self.data)\n",
    "                    similarities.append((item_sim, item, unrated_item))\n",
    "        item_near = {}\n",
    "        # we create a dictionary in which we compute the similarities of every\n",
    "        # top rated item to other top rated items, where top rated items are keys\n",
    "        # and list of similarity to an item and item itself as tuples are elements\n",
    "        # of that list\n",
    "        for sim, item, near_item in similarities:\n",
    "            if item in item_near:\n",
    "                item_near[item].append((sim, near_item))\n",
    "            else:\n",
    "                item_near[item] = [(sim, near_item)]\n",
    "        # sort the values according to their similarity, highest similarity \n",
    "        # at top\n",
    "        for key, rating in item_near.items():\n",
    "            rating.sort(key=lambda sim: sim[0], reverse=True)\n",
    "        recommendations = [item_near[item][0] for item in item_near]\n",
    "        # remove duplicate items, remove the duplicate with lower item similarity\n",
    "        for sim, item in recommendations:\n",
    "            for sim2, item2 in recommendations:\n",
    "                if item == item2 and sim < sim2:\n",
    "                    recommendations.remove((sim, item))\n",
    "                elif item == item2 and sim > sim2:\n",
    "                    recommendations.remove((sim2, item2))\n",
    "        final_recoms = [elems[1] for elems in recommendations]\n",
    "        return user, (final_recoms)\n",
    "    \n",
    "# rec = recommender(users, k=3)\n",
    "# print(rec.recommend(\"Veronica\"))\n",
    "#rec.load_book_db('/Users/ubmenderes/Downloads/BX-Dump/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering in Classic Recommender Systems\n",
    "\n",
    "In classic recommenders, the task of user-based **Collaborative Filtering** is handled by computations on user data and the associated databases, which are mainly dictionaries/associative arrays. Collaborative Filtering follows the idea that an item may be recommended to a user if one finds out what kind of items other uses liked or also disliked, this is the *collaborative* part of the method. In other words: If I like certain items and another users likes those items the same way I do, I also might like the items that that other user has rated positively but which I have *not rated* yet. One problem that one might already spot is that this requires users to be somewhat honest and serious about their ratings, since dishonesty in the rating behaviour would influence the databases of users and thus would ultimately skew the computations and their results performed on these datasets. Problematic platforms in which this phenomenon could occur are platforms which are subject to heavy user bias such as YouTube, where the like/dislike ratio isn't necessarily a reflection of the content quality but often ends up being a ratio to determine the current likability of a YouTuber. However, on platforms like IMDB, Metacritic, Amazon, Letterboxd etc., collaborative filtering with emphasis on user ratings could work out fairly well since users on these sites tend to be more objective when rating items. Another way of working around this could be alternative implementations which take into account other factors such as genre, production company, production year etc, but I will not focus on these in this notebook and solely work on ratings.<br>\n",
    "\n",
    "### Similarity measures - Minkowsi Distance, Manhattan Distance and Euclidean Distance\n",
    "In the class above, we handle this by introducing and applying **similarity measures** which, in collaborative filtering, measure the similarity of one user to other users of a certain platform/dataset. One such measure is the **Minkowski-Distance**, which is based on this formula:\n",
    "$$d(x,y) = (\\sum_{k=1}^n |x_k - y_k|^p)^{\\frac{1}{p}}$$\n",
    "$x$ and $y$, respectively, thus represent two users as variables, and our target is to find the related distance between them.\n",
    "Below is the specific implementation in the *recommender* class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(self, rating1, rating2, p):\n",
    "        \"\"\"\n",
    "        Implementation of Minkowski distance formula\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rating1 : dict\n",
    "            dictionary in which the ratings of user1 are specified, \n",
    "            passing as argument into function via \"users['users']\"\n",
    "        rating2 : dict\n",
    "            dictionary in which ratings of user2 are specified, same \n",
    "            argument passing conventions as above\n",
    "        p : int\n",
    "            specifies parameter 'p' in minkowski distance formula\n",
    "            p = 1 --> Manhattan distance\n",
    "            p = 2 --> Euclidean distance\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            returns the minkowski distance measure between rating1 and rating 2\n",
    "            according to parameter 'p'\n",
    "\n",
    "        \"\"\"\n",
    "        distance = 0\n",
    "        common_ratings = False\n",
    "        for key in rating1:\n",
    "            if key in rating2:\n",
    "                distance += pow(abs(rating1[key] - rating2[key]), p)\n",
    "                common_ratings = True\n",
    "        if common_ratings == True:\n",
    "            return pow(distance, 1/p)\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of the Minkowski Distance metric is that two popular distance metrics from linear algebra, namely **Manhattan-Distance** and **Euclidean Distance** are already included in the Minkowski-Distance, since selecting parameter $p=1$ will give us Manhattan Distance, while choosing $p=2$ gives us Euclidean Distance. With this, we can measure the distance between two users, or to be more precise the difference between the ratings they gave to items rated commonly between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Measures - Cosine Similarity\n",
    "Another popular metric measuring simialarity between two users is **Cosine Similarity**:\n",
    "$$cos(x,y) = \\frac{x\\cdot y}{||x||\\cdot ||y||}$$.\n",
    "Cosine similarity metric maps the similarity value to an interval of $[-1, 1]$, where 1 naturally indicates best similarity (i.e. equality) and -1 indicates complete divergence. Below is the implementation of cosine similarity in the recommender class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(self, rating1, rating2):\n",
    "        \"\"\"\n",
    "        Implementation of cosine similarity w.r.t to given datastructures at hand\n",
    "        Measures similarity between two users by measuring ratings\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rating1 : dict \n",
    "            user ratings for user 1, dict must be indiced and indexing must be \n",
    "            passed as function argument in form of (users['user'])\n",
    "        rating2 : dict\n",
    "            user ratings for user 2, same as above \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cosine similarity\n",
    "            alternative measure for capturing the similarity between two users, \n",
    "            ranges from -1 to 1\n",
    "\n",
    "        \"\"\"\n",
    "        num = self.dot(rating1, rating2)\n",
    "        sum_r1 = []\n",
    "        sum_r2 = []\n",
    "        for vals in rating1.values():\n",
    "            sum_r1.append(pow(vals, 2))\n",
    "        for vals in rating2.values():\n",
    "            sum_r2.append(pow(vals, 2))\n",
    "            denom = sqrt(sum(sum_r1)) * sqrt(sum(sum_r2))\n",
    "        return num / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User similarity measures - Pearson correlation coefficient\n",
    "The last user similarity measure that I want to introduce here is the **Pearson correlation coefficient**, an apparently well known metric in statistics. Like in the other measures already presented, our users are represented in the form of variables $x$ and $y$, and our task yet again consists in finding out the distance between them, which in this case means measuring the similarity between them by analyzing their ratings. Like cosine similarity, Pearson correlation coefficient maps our similarity value to an intervall of $[-1, 1]$, where 1 means *total positive linear correlation* (i.e. the users and their ratings are practically the same), -1 means *total negative linear correlation* and 0 means no linear correlation whatsoever. The formula for the coefficient, which is also commonly known as *Pearson r* is as follows:\n",
    "$$r = \\frac{\\sum^n_{i=1}(x_i - \\tilde{x})(y_i-\\tilde{y})}{\\sqrt{\\sum^n_{i=1}}(x_i - \\tilde{x})^2 \\sqrt{\\sum_{i=1}^n}(y_i - \\tilde{y})^2}$$\n",
    "Since this formula is unnecessarily difficult to program, an approximation (which still satisfies the desired objective) is chosen instead.\n",
    "The implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(self, rating1, rating2):\n",
    "        \"\"\"\n",
    "        Implementation of Pearson correlation coefficient formula\n",
    "        Calculates similarity of users via ratings ina given dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rating1 : dict\n",
    "            ratings of the first user, access via \"users[user]\"\n",
    "        rating2 : dict\n",
    "            ratings of 2nd user, same accessing conventions when passing \n",
    "            in the argument\n",
    "        function implements pearson similarity metric by comparing commonly rated \n",
    "        elements of both users\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            returns a float which measures the similarity of two user according \n",
    "            to their set of commonly given ratings, ranges from -1 to 1\n",
    "\n",
    "        \"\"\"\n",
    "        sum_xy = 0\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        sum_x2 = 0\n",
    "        sum_y2 = 0\n",
    "        n = 0\n",
    "        for key in rating1:\n",
    "            if key in rating2:\n",
    "                n += 1\n",
    "                x = rating1[key]\n",
    "                y = rating2[key]\n",
    "                sum_xy += x * y\n",
    "                sum_x += x\n",
    "                sum_y += y\n",
    "                sum_x2 += pow(x, 2)\n",
    "                sum_y2 += pow(y, 2)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        # compute denominator\n",
    "        denominator = (sqrt(sum_x2 - pow(sum_x, 2) / n)\n",
    "                       * sqrt(sum_y2 - pow(sum_y, 2) / n))\n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (sum_xy - (sum_x * sum_y) / n) / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sense of the similarities - KNN Approach\n",
    "As previously mentioned, these similarity metrics are all used to measure to how similar users from given datasets are to one another. However, this is just one half of the collaborative filtering approach, as similarities by themselves are not sufficient in order to make the actual recommendation (and a possible prediction). In order to be able to recommend an item to a certain user, we must make use of one of the earliest machine learning algorithms - **K-nearest neighbors**. With KNN, we determine the $k$ nearest users to a given user with our chosen similarity metric, which means that ultimately we determine the k-most-similar users to an input user, analyze their ratings, calculate the respective contribution of each user to the final recommendation and predicted rating and return the recommendation with predicted rating as output. Naturally, the items that both users already rated fall out here, so we can only recommend items from the nearest neighbors that the user hasn't rated yet. Below is the implementation for both KNN and recommendation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(self, username):\n",
    "        \"\"\"\n",
    "        Determines nearest neighbors, i.e. users for a user in a given dataset\n",
    "        for collaborative filtering.\n",
    "        Default metric is Pearson correlation coefficient, can be changed to other\n",
    "        metrics when instatiating an object of Recommender class \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        username : str\n",
    "            username of a user in the set of our users\n",
    "        \n",
    "        since self.fn == 'pearson', the nearest neighbors will be calculated \n",
    "        using pearson coefficient, can be changed if desired\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        distances : list\n",
    "            a list containing all the distances from the user to the other users\n",
    "            in the total set of users\n",
    "            Elements are tuples with users (str) as first element and the distances\n",
    "            to them as floats as second element\n",
    "\n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        for instance in self.data:\n",
    "            # measure distance only if users are distinct \n",
    "            if instance != username:\n",
    "                # Pearson metric is applied\n",
    "                distance = self.fn(self.data[username], self.data[instance])\n",
    "                distances.append((instance, distance))\n",
    "        distances.sort(key=lambda artist_tuple: artist_tuple[1], reverse=True)\n",
    "        return distances\n",
    "    \n",
    "    def recommend(self, user:str):\n",
    "        \"\"\"\n",
    "        Recommends a \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            user in the set of users\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        type = list\n",
    "            returns a list of top n recommendations for the user \n",
    "\n",
    "        \"\"\"\n",
    "        # create empty dictionary for recommendations\n",
    "        recommendations = {}\n",
    "        # compute the nearest neighbors of a specific user\n",
    "        nearest = self.nearest_neighbor(user)\n",
    "        # extract ratings for this specific user from self.data dict\n",
    "        user_ratings = self.data[user]\n",
    "        # initialize total distance counter\n",
    "        total_distance = 0.0\n",
    "        # iterate over k elements, here k=1\n",
    "        for i in range(self.k):\n",
    "            total_distance += nearest[i][1]\n",
    "        # add up the total distance by summing over the ratings of k nearest neighbors\n",
    "        # compute the contribution of each k neighbor\n",
    "        for i in range(self.k):\n",
    "            weight = nearest[i][1] / total_distance\n",
    "            # extract name of each of the k neighbors\n",
    "            name = nearest[i][0]\n",
    "            # extract ratings of each person out of the k neighbors\n",
    "            neighbor_ratings = self.data[name]\n",
    "        # for every artist in neighbor ratings\n",
    "        for artist in neighbor_ratings:\n",
    "            # if the artist is not in the user_ratings\n",
    "            if not artist in user_ratings:\n",
    "                # and if the artist is not already in recommendations dict \n",
    "                # i.e. artists that the neigbor rated but the user didn't\n",
    "                # for key artists, assign the value of its neighbor rating times the weight \n",
    "                # it contributes\n",
    "                if artist not in recommendations:\n",
    "                    # for key artists, assign the value of its neighbor rating times the weight \n",
    "                    # it contributes\n",
    "                    recommendations[artist] = (neighbor_ratings[artist]*weight)\n",
    "                else:\n",
    "                    # if artist already existing, assign neighbor rating + recommendations rating\n",
    "                    # and multiply it with weight\n",
    "                    recommendations[artist] = (recommendations[artist]+neighbor_ratings[artist] * weight)\n",
    "        # make a list out of the key, value pairs of artist and recommendations tuples\n",
    "        recommendations = list(recommendations.items())\n",
    "        # convert the product id to names via list comprehension\n",
    "        recommendations = [(self.convertProductID2name(k), v) for (k, v) in recommendations]\n",
    "        # sort the list by rating, reverse in order for top ratings to be at the beginning\n",
    "        recommendations.sort(key=lambda artist_tuple: artist_tuple[1], reverse=True)\n",
    "        # return n elements\n",
    "        return recommendations[:self.n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering thus provides a great way to create recommendations by following a very simple thought: An item that is liked by user will possibly be liked by similar users with similar tastes. As noted, it does have a few shortcomings such as absolute honesty from users when rating the items, or also the necessity of a considerably larger dataset of users (since we want to cover as similar users as possible), still, it appears to be very popular since it is also used by sites such as YouTube, where some video recommendations are marked with \"users who have watched this also watched this video\", and, as I will later show later on, it is also a popular base model for both *Neural Collaborative Filtering*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based filtering\n",
    "Item-based filtering flipts the script and approaches the task of recommending from the perspective (and accesability) of the respective **items** that we rate and want to recommend. As Rob Zacharski suggests, the motivation behind item-based filtering is that users on certain platforms can often times be biased in their ratings and thus can fundamentally influence various different computations mentioned above for the worse. In order to overcome this phenomenon, data scientists have figured out that instead of performing various distance and similarity measures on users, it might be more suitable to perform these computations (with same databases as in collaborative filtering) on items instead. An especially brilliant method (which blows the proportions of this project, but is still worth mentioning) is **implicit ratings**, where users are not required to rate an item on any fixed scale; instead, other factors which don't require the user to perform any kind of direct rating such as *screen time for a certain item*, *searching frequency*, *number of times played/watched* etc. are taken into account. It is to be noted, however, that implicit ratings aren't free of flaws as well, since **outliers** in our patterns could skew the recommendations as well.<br>\n",
    "In the class above, the task of item-based filtering is handled by *slope_one_recommender* function, which is based on the code from Rob Zacharski's *The Ancient Art of the Numerati*. I also added the *predict_rating* function which is based on adjusted cosine similarity and, as the name suggests, also returns a prediction for an item that is recommended to a user. In addition to that, I added the *nearest_items* function which works on the premise that items that are similar to the top rated items of a user might also be well received by the user, hence we recommend them to him/her. The logic behind this idea was that a user (depending on the platform) is likely to give the highest rating only to a few selected items. Since we already excluded the items that the user has already rated, finding out the most similar items to the highest rated items of a user gives us a good base of recommending items that a user might like, given the similarity to his favourite items. This can, however, be prone to outliers in the user's highest rated items, since an item of (for example) a completely different genre than the other items in his favourites could recommend items that are not necessarily the user's usual taste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_deviations(self):\n",
    "        \"\"\"\n",
    "        Computes item deviations in a given dataset \n",
    "        \n",
    "        args: self, no other argument necessary\n",
    "        \n",
    "        Functions computes deviations for each item according to the given \n",
    "        formula in Chapter 3 of \"The ancient art of Numerati\"\n",
    "        \n",
    "        After function is called, self.deviations will be filled with each item \n",
    "        as key, and its values are dictionaries in which keys represent other items \n",
    "        and values represent the deviation to that item in float type\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        # for each person in the data :\n",
    "        #get their ratings\n",
    "        for ratings in self.data.values():\n",
    "            #for each item and its rating in tthe ratings dict\n",
    "            for (item, rating) in ratings.items():\n",
    "                self.frequencies.setdefault(item, {})\n",
    "                self.deviations.setdefault(item, {})\n",
    "                # for each item2 & rating2 in that set of ratings: \n",
    "                for(item2, rating2) in ratings.items():\n",
    "                    # add the difference between the ratings to our computation\n",
    "                    if item != item2:\n",
    "                        self.frequencies[item].setdefault(item2, 0)\n",
    "                        self.deviations[item].setdefault(item2, 0.0)\n",
    "                        self.frequencies[item][item2] += 1\n",
    "                        self.deviations[item][item2] += rating - rating2\n",
    "        for (item, ratings) in self.deviations.items():\n",
    "            for item2 in ratings:\n",
    "                ratings[item2] /= self.frequencies[item][item2]\n",
    "    \n",
    "        \n",
    "    def slope_one_recommend(self, user):\n",
    "        \"\"\"\n",
    "        Implementation of slope one algorithm for recommendation and \n",
    "        prediction of an item for a given user, for item-based recommendation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            user for which we will recommend items and predict his ratings\n",
    "            self.compute_deviations function must be called before calling this \n",
    "            function\n",
    "            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        recommendations : list\n",
    "            A list containing tuples as elements\n",
    "            tuple[0] = item which user hasn't rated yet, type: str\n",
    "            tuple[1] = predicted rating for that unrated item, type: float\n",
    "\n",
    "        \"\"\"\n",
    "        self.compute_deviations()\n",
    "        recommendations = {}\n",
    "        frequencies = {}\n",
    "        # for every item and rating in the user's recommendations\n",
    "        for (user_item, user_rating) in self.data[user].items():\n",
    "            # for every item in our dataset that the user didn't rate\n",
    "            # example. dict_items([('Taylor Swift', 5), ('PSY', 2)])\n",
    "            for (diff_item, diff_ratings) in self.deviations.items():\n",
    "                if diff_item not in self.data[user] and \\\n",
    "                   user_item in self.deviations[diff_item]:\n",
    "                # get the deviations, frequencies for the item that wasn't rated\n",
    "                # but only if a value for deviations exists and diff_item is not \n",
    "                # in user_ratings\n",
    "                    freq = self.frequencies[diff_item][user_item]\n",
    "                    # get the frequency of diff_item and user_item, \n",
    "                    # key in frequencies is the different item, second dict indice \n",
    "                    # is the frequency with user_item\n",
    "                    recommendations.setdefault(diff_item, 0.0)\n",
    "                    frequencies.setdefault(diff_item, 0)\n",
    "                    # add to the running sum representing the numerator\n",
    "                    # of the formula \n",
    "                    # diff_item is key, result of formula is value\n",
    "                    recommendations[diff_item] += (diff_ratings[user_item] +\n",
    "                                                   user_rating)* freq\n",
    "                    # keep a running sum of the frequency of diffitem\n",
    "                    frequencies[diff_item] += freq\n",
    "        recommendations = [(self.convertProductID2name(k), v / frequencies[k])\n",
    "                           for (k, v) in recommendations.items()]\n",
    "        recommendations.sort(key=lambda artist_tuple: artist_tuple[1], reverse = True)\n",
    "        return recommendations\n",
    "    \n",
    "def item_similarity(self, artist1, artist2, user_ratings):\n",
    "        \"\"\"\n",
    "        Computes the similarity between two items in a given dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        artist1 : str\n",
    "            artist1 for which we will compute the similarity with artist2, must be \n",
    "            in user_ratings dict\n",
    "        artist2 : str\n",
    "            artist1 for which we will compute the similarity with artist2, must be \n",
    "            in user_ratings dict    \n",
    "        user_ratings : dict\n",
    "            dictionary containing users as keys, their ratings for items \n",
    "            as internal dict as values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            similarity between two items\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        averages = {}\n",
    "        for (key, ratings) in user_ratings.items():\n",
    "            #take the values of the internal dict, sum over each value and divide by length of values\n",
    "            averages[key] = (float(sum(ratings.values()))\n",
    "                      / len(ratings.values()))\n",
    "        numerator = 0\n",
    "        denom1 = 0\n",
    "        denom2 = 0\n",
    "        for (user, ratings) in user_ratings.items():\n",
    "            #if the users rated both artists\n",
    "            if artist1 in ratings and artist2 in ratings:\n",
    "                #compute the averages of each user\n",
    "                avg = averages[user]\n",
    "                # in ratings dict, artists are the keys and their respective values, \n",
    "                # which we access via indexing, are their ratings\n",
    "                # those ratings for the artists are subtracted by the average of each user\n",
    "                # and then multiplied\n",
    "                numerator += (ratings[artist1] - avg) * (ratings[artist2] - avg)\n",
    "                denom1 += (ratings[artist1]-avg)**2 \n",
    "                denom2 += (ratings[artist2]-avg)**2\n",
    "        return numerator / (sqrt(denom1) * sqrt(denom2))\n",
    "    \n",
    "def normalized_rating(self, user:str, item:str):\n",
    "        \"\"\"\n",
    "        Normalizes the rating of an item for a user in a given dataset according \n",
    "        to minimum and maximum rating of that dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            a user who has rated the item function argument\n",
    "        item : str\n",
    "            item that a user has rated, is within the internal dictionary as key\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            normalized rating for a user given said item\n",
    "\n",
    "        \"\"\"\n",
    "        global min_rat\n",
    "        global max_rat\n",
    "        min_ratings = []\n",
    "        max_ratings = []\n",
    "        for (key, rating) in self.data.items():\n",
    "            key_max = max(rating.keys(), key=(lambda k: rating[k]))\n",
    "            key_min = min(rating.keys(), key=(lambda k: rating[k]))\n",
    "            min_ratings.append(rating[key_min])\n",
    "            max_ratings.append(rating[key_max])\n",
    "        min_rat = min(min_ratings)\n",
    "        max_rat = max(max_ratings)\n",
    "        if item in self.data[user]:\n",
    "            return (2*((self.data[user][item]-min_rat)) - (max_rat-min_rat)) / (max_rat-min_rat)\n",
    "            \n",
    "    \n",
    "def denormalized_rating(self, user:str, item:str):\n",
    "        \"\"\"\n",
    "        Returns a normalized rating back into a scaled rating, \n",
    "        given respective rating scale\n",
    "        \n",
    "        BEWARE!!! This function takes an user and an item and then gives the denormalized\n",
    "        rating for it, the denormalizer only takes a float value\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            DESCRIPTION.\n",
    "        norm_rating : float\n",
    "            DESCRIPTION.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        return (0.5*((self.normalized_rating(user, item)+1) * (max_rat-min_rat))) + min_rat\n",
    "        \n",
    "    \n",
    "def denormalize(self, norm_rating:float):\n",
    "        \"\"\"\n",
    "        Function for denormalizing a rating\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        norm_rating : float\n",
    "            DESCRIPTION.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        return (0.5*((norm_rating+1) * (max_rat-min_rat))) + min_rat\n",
    "\n",
    "        \n",
    "def predict_rating(self, user:str, item:str):\n",
    "        \"\"\"\n",
    "        Predicts the rating of an item from a user from a given dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user : str\n",
    "            user in a given dataset\n",
    "        item : str\n",
    "            an item which the user HAS NOT rated yet\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            tuple[0] = user \n",
    "            tuple[1] = item recommended for that user\n",
    "            tuple[2] = predicted rating for that item\n",
    "\n",
    "        \"\"\"\n",
    "        #initiate numerator and denumerator of formula\n",
    "        denom = 0\n",
    "        numerator = 0\n",
    "        for rated_item in self.data[user]:\n",
    "            if rated_item in self.data[user]:\n",
    "                denom += (self.item_similarity(rated_item, item, self.data)\n",
    "                          *self.normalized_rating(user, rated_item))\n",
    "                numerator += abs(self.item_similarity(item, rated_item, self.data))\n",
    "        return (user, item, self.denormalize(denom/numerator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that both Collaborative Filtering and Item-Based Recommending work mainly on the mathematical basis of **Similarity Measures** such as cosine distance, Pearson Correlation Coefficient etc., and are slighlty adapted to properly handle the task of recommending at hand. During my experiments with the manual datasets, I personally found Item-Based filtering more intriguing since it not only recommends items for a given user, but also predicts the rating (according to the parametrization one chooses) for these recommended items.<br>\n",
    "Certain characteristics of Classical Recommenders include that the Data always has to be preprocessed in a way that it can be appropriately handled, i.e. choosing the right data format in associative arrays and filling them such that every rating can be associated to an item, with these arrays then again associated with a unique user. My experience also included an unsatsisfyingly long loading time for calculating the deviations, which is caused by the fact that the larger a dataset is the mor time all these mathematical calculations will take up time to calculate and return results (I waited for 30 Minutes until my MacBook crashed). It is also worth noting that classic recommender systems can only expand in their variety of similarity measures, since the data stays the same and cannot be e.g. embedded, which then again would enable other calculations to which I will come later in this notebook <br>\n",
    "Because of this, I would personally deem classic recommender systems to be a good fit for smaller datasets or datasets which are can be easily split into smaller parts, at least if you don't have a computer strong enough to calculate necessary calculations in appropriate time.<br>\n",
    "Item-based filtering attempts to circumnavigate the sheer unreliability of users, but since even item-based recommendations are somewhat linked to user-item interactions, they can't pass this barrier completely either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Neural Recommenders and Classic Recommenders\n",
    "As can be seen here, the classic recommenders require more accurate detailed computations and a strong database in order to yield a feasible result, but if that's provided by implementation, than they are guaranteed to produce feasible results, except for the outliers where even they can't properly predict a good rating, if any rating at all. However, the versatility they offer via implementation of both collaborative filtering and item-based filtering is a great advantage if one were to desire to be able to recommend on the basis of both methods.<br>\n",
    "Collaborative filtering with Neural Networks and Matrix Factorization, on the other hand, provides for an interesting method implementing and realizing the task of collaborative filtering as it primarily works with embeddings. However, my findings showed that Neural Collaborative Filtering depends on a strong database where as much of observations of each rating has to be given, since otherwise the predictions will be inaccurate to the model being biased towards ratings that is sees more often. Another problem is **Bias/Variance** since greatly overfitting the model will result in inaccurate predictions which thus negatively affects the final recommendations. The Neural Network model seemed to have the least problems with this, however, it also could have performed better, and given approprite conditions (e.g. strong CPU which can quickly calculate 1000 epochs), it could also provide better results. An advantage of Neural Models is that they are quite open to adjustment and extension; a model doesn't have to remain rigidly the same but one can experiment with many factors which could further improve the model's perfomance: hyperparameter, model architecture, embedding size etc. Every recommender has something in commmon, though: They each suffer from the tendency of Collaborative Filtering to recommend the most popular items and predict a high score them. Though this underlines the very notion of Collaborative Filtering actually, it is sometimes not quite what a powerful recommender should do, for there are users with peculiar tastes whose interests will not be satisfied by recommending them the most popular items. Still, for most usecases, (Neural) Collaborative Filtering should provide a good approach to the task of making effective recommendations for users of any given platform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
